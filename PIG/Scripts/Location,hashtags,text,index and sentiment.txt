--UDF imports 
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/elephant-bird-hadoop-compat-4.1.jar';
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/elephant-bird-pig-4.1.jar';
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/elephant-bird-core-4.1.jar';
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/json-simple-1.1.1.jar';
--REGISTER '/usr/hdp/2.6.5.0-292/hive/lib/hcatalog-core-0.11.0.jar';

--Load Data and defining schema 
load_tweets = LOAD '/user/flume/tweets/' USING PigStorage('\n') AS (line:chararray,location:chararray,hashtags:chararray,cnt:int);
DEFINE JsonStringToMap com.twitter.elephantbird.pig.piggybank.JsonStringToMap();
Data = FOREACH load_tweets GENERATE JsonStringToMap(line);

--limit recorsds to be evaluated 
--Data = LIMIT Data 10000;

--Declaring Data sets 
tweet_info = FOREACH Data GENERATE 
json#'created_at' AS created_at,
JsonStringToMap(json#'user')#'screen_name' AS username,
json#'id' AS id:int, 
json#'lang' AS lang, 
json#'text' AS text,
JsonStringToMap(json#'user')#'location' AS location;

--Filter Null locations 
filtered_data = FILTER tweet_info BY location IS NOT NULL 
                    AND location =='Bengaluru South' 
                    OR location =='Bengaluru'
                    OR location =='Chennai'
                    OR location =='Hyderabad' 
                    OR location =='Mumbai' 
                    OR location =='Kolkata'
                    OR location =='Ahmedabad' 
                    OR location =='Pune'
                    OR location =='Surat' 
                    OR location =='Patna' 
                    OR location =='Delhi'
                    OR location =='Visakhapatnam'
                    OR location =='Kanpur'
                    OR location =='Gurgaon'
                    OR location =='Noida'
                    OR location =='Rajendran Nagar'
                    OR location =='Jaipur'
                    OR location =='Haveli'
                    OR location =='Navi Mumbai'
                    OR location =='Lucknow'
					OR location =='Varanasi';
                    

-- Remove non-characters except for # and @
tweets = FOREACH filtered_data GENERATE location, REPLACE(text,'([^a-zA-Z0-9#@\\s]+)', '') AS text;

-- Tokenize each tweet message
tweetwords = FOREACH tweets GENERATE location,text, FLATTEN( TOKENIZE(text) ) AS word, FLATTEN( TOKENIZE(text) ) AS words;

-- Search for only hashtags in the tweets
hashtags = FILTER tweetwords BY UPPER(word) MATCHES '#\\s*(\\w+)';

tokens = foreach hashtags generate word, words, location, text ;


--Importing AFFIN Dictionary with word and rating fields:-
dictionary = load '/AFFIN_Dictionary/AFINN-111.txt' using PigStorage('\t') AS (word:chararray,rating:int);

--joining tokens and word by dictionary:- 
word_rating = join tokens by words left outer, dictionary by word using 'replicated';

--describe word_rating;

--generating id, text and rating:-
rating = foreach word_rating generate tokens::location as location,tokens::word as word,tokens::text as text, dictionary::rating as rate;

--grouping:- 
word_group = group rating by (location,word);   --i removed "text" as it brings text to the data 

--generating average rating for each (id,text):-
avg_rate = foreach word_group generate group as gp, AVG(rating.rate) as tweet_rating;

--filtering tweets with no ratings:-
f1_filter  = Filter avg_rate by tweet_rating is not NULL;

sortter = foreach f1_filter generate flatten (gp), tweet_rating,
(
 CASE
   WHEN tweet_rating >= 3.0 THEN 'Strong Positive'
   WHEN tweet_rating > 0.0 and  tweet_rating < 3.0 THEN 'Positive'
   WHEN tweet_rating == 0.0 THEN 'neutral'
   WHEN tweet_rating < 0.0 and  tweet_rating > -3.0 THEN 'negative'
   WHEN tweet_rating <= -3.0 THEN 'Strong negative'
 END
);


dump sortter;

STORE sortter INTO '/user/flume/tweet_sentiment_data.csv' using PigStorage(',');


