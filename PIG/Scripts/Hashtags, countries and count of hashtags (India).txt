--UDF imports 
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/elephant-bird-hadoop-compat-4.1.jar';
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/elephant-bird-pig-4.1.jar';
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/elephant-bird-core-4.1.jar';
REGISTER '/usr/hdp/2.6.5.0-292/pig/lib/json-simple-1.1.1.jar';
--REGISTER '/usr/hdp/2.6.5.0-292/hive/lib/hcatalog-core-0.11.0.jar';

--Load Data and defining schema 
load_tweets = LOAD '/user/flume/tweets/' USING PigStorage('\n') AS (line:chararray,location:chararray,hashtags:chararray,cnt:int);
DEFINE JsonStringToMap com.twitter.elephantbird.pig.piggybank.JsonStringToMap();
Data = FOREACH load_tweets GENERATE JsonStringToMap(line);

--limit recorsds to be evaluated 
--Data = LIMIT Data 10000;

--Declaring Data sets 
tweet_info = FOREACH Data GENERATE 
json#'created_at' AS created_at,
JsonStringToMap(json#'user')#'screen_name' AS username,
json#'id' AS id:int, 
json#'lang' AS lang, 
json#'text' AS text,
JsonStringToMap(json#'user')#'location' AS location;

--Filter Null locations 
filtered_data = FILTER tweet_info BY location IS NOT NULL 
                    AND location =='Bengaluru South' 
                    OR location =='Bengaluru'
                    OR location =='Chennai'
                    OR location =='Hyderabad' 
                    OR location =='Mumbai' 
                    OR location =='Kolkata'
                    OR location =='Ahmedabad' 
                    OR location =='Pune'
                    OR location =='Surat' 
                    OR location =='Patna' 
                    OR location =='Delhi'
                    OR location =='Visakhapatnam'
                    OR location =='Kanpur'
                    OR location =='Gurgaon'
                    OR location =='Noida'
                    OR location =='Rajendran Nagar'
                    OR location =='Jaipur'
                    OR location =='Haveli'
                    OR location =='Navi Mumbai'
                    OR location =='Lucknow'
                    OR location =='Varanasi';

-- Remove non-characters except for # and @
tweets = FOREACH filtered_data GENERATE location, REPLACE(text,'([^a-zA-Z0-9#@\\s]+)', '') AS text;

-- First finding hashtags(#)
-- Tokenize each tweet message
tweetwords = FOREACH tweets GENERATE location, FLATTEN( TOKENIZE(text) ) AS word;

-- Search for only hashtags in the tweets
hashtags = FILTER tweetwords BY UPPER(word) MATCHES '#\\s*(\\w+)';

box1 = GROUP hashtags BY (word,location);

box2 = FOREACH box1 GENERATE group AS loc, COUNT(hashtags) AS cnt ;

box3 = FOREACH box2 GENERATE FLATTEN(loc),cnt;

--gp = FOREACH grouper GENERATE group AS location, COUNT(hashtags) AS cnt; 
--f = order gp by cnt desc;
--Tags = limit f 1000;

DUMP box3;

STORE box3 INTO '/user/flume/tweet_data.csv' using PigStorage(',');